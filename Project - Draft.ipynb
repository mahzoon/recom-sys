{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "books = pd.read_csv('./data/BX-Books.csv', sep=';', quotechar='\"', escapechar='\\\\', header=0)\n",
    "users = pd.read_csv('./data/BX-Users.csv')\n",
    "ratings_train = pd.read_csv('./data/BX_train.csv',\n",
    "                            header=None, names=['UserID', 'BookID', 'Rating'])\n",
    "ratings_test = pd.read_csv('./data/BX_test.csv',\n",
    "                           header=None, names=['UserID', 'BookID', 'Rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebuilding train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_submission = ratings_test[ratings_test.Rating == 55]\n",
    "tmp = ratings_test[ratings_test.Rating != 55]\n",
    "train_explicit = ratings_train[ratings_train.Rating != 0]\n",
    "train_explicit = train_explicit.append(tmp)\n",
    "train_implicit = ratings_train[ratings_train.Rating == 0]\n",
    "#pickle.dump(train_explicit, open('./data/input_1.pcl', 'wb'))\n",
    "#pickle.dump(test_submission, open('./data/submission.pcl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading saved inputs (run this to skip \"converting implicit feedbacks\" section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_explicit = pickle.load(open('./data/input_1.pcl', 'rb'))\n",
    "train_all = pickle.load(open('./data/input_2.pcl', 'rb'))\n",
    "test_submission = pickle.load(open('./data/submission.pcl', 'rb'))\n",
    "# user_item_matrix_1 = pickle.load(open('user_item_matrix_1.pcl', 'wb'))\n",
    "# user_item_matrix_2 = pickle.load(open('user_item_matrix_2.pcl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting implicit feedbacks to ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that we want to convert the implicit rating for item i for user u, and I is the set of other users who rated item i. Then:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ R_{ui} = \\mu_{u} + \\frac{\\sum_{s\\in{I}}{(R_{si} - \\mu_{s})}}{len(I)} + \\lambda $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The first term is the average rating value for user u\n",
    "* The second term is the unbiased goodness of item i, which is the average unbiased current explicit ratings. To calculate this, assume that I is the set of users who explicitly rated the item i. Then the average unbiased ratings of item i would be the average distance of explicit ratings and average user ratings. \n",
    "* The third term (lambda) is the implicit rating constant. This can be set to 1 in a rating scale of 10.\n",
    "* For 'new user' situation we consider average of all ratings (~7.57) for the first term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improvement: change $$ \\lambda \\space --> \\space \\lambda * number\\space of\\space implicit\\space feedback\\space for\\space item\\space i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_explicit_grouped_by_user = train_explicit[['UserID', 'Rating']].groupby('UserID')\n",
    "adjusted_ratings = train_explicit.copy()\n",
    "adjusted_ratings['Rating'] = train_explicit['Rating'] - \\\n",
    "                            train_explicit_grouped_by_user.transform('mean')['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_explicit_item_mean = adjusted_ratings.groupby('BookID').mean()['Rating'].to_dict()\n",
    "train_explicit_user_mean = train_explicit_grouped_by_user.mean()['Rating'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_implicit_conversion = train_implicit.copy()\n",
    "train_implicit_conversion['Rating'] = train_implicit_conversion.Rating.astype(pd.np.float64)\n",
    "counter = 1\n",
    "max_counter = len(train_implicit_conversion)\n",
    "update_step = max_counter / 10\n",
    "baseline_rating = train_explicit.Rating.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, row in train_implicit_conversion.iterrows():\n",
    "    term1 = 0\n",
    "    if row.UserID in train_explicit_user_mean:\n",
    "        term1 = train_explicit_user_mean[row.UserID]\n",
    "    else:\n",
    "        term1 = baseline_rating\n",
    "    term2 = 0\n",
    "    if row.BookID in train_explicit_item_mean:\n",
    "        term2 = train_explicit_item_mean[row.BookID]\n",
    "    term3 = 1 if (term1 + term2) < 9 else 0\n",
    "    rating = term1 + term2 + term3\n",
    "    if rating < 1:\n",
    "        rating = 1\n",
    "    if rating > 10: # impossible!\n",
    "        rating = 10\n",
    "    train_implicit_conversion.set_value(i, 'Rating', rating)\n",
    "    if counter % update_step == 0:\n",
    "        clear_output()\n",
    "        print str(counter * 100 / max_counter) + \"%\"\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_all = train_explicit.append(train_implicit_conversion)\n",
    "pickle.dump(train_all, open('./data/input_2.pcl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Book ID padding problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_explicit['BookID_org'] = train_explicit['BookID']\n",
    "train_explicit['BookID'] = train_explicit['BookID'].apply(lambda x: x.zfill(10))\n",
    "train_all['BookID_org'] = train_all['BookID']\n",
    "train_all['BookID'] = train_all['BookID'].apply(lambda x: x.zfill(10))\n",
    "test_submission['BookID_org'] = test_submission['BookID']\n",
    "test_submission['BookID'] = test_submission['BookID'].apply(lambda x: x.zfill(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing BookID with books' features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_explicit_1 = train_explicit.merge(books, left_on='BookID', right_on='ISBN', how='left')\n",
    "train_all_1 = train_all.merge(books, left_on='BookID', right_on='ISBN', how='left')\n",
    "test_submission_1 = test_submission.merge(books, left_on='BookID', right_on='ISBN', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_explicit_missing_item = train_explicit_1[train_explicit_1.isnull().any(axis=1)]\n",
    "train_all_missing_item = train_all_1[train_all_1.isnull().any(axis=1)]\n",
    "test_submission_missing_item = test_submission_1[test_submission_1.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(str(len(train_explicit_missing_item)) + \" / \" + str(len(train_explicit)))\n",
    "print(str(len(train_all_missing_item)) + \" / \" + str(len(train_all)))\n",
    "print(str(len(test_submission_missing_item)) + \" / \" + str(len(test_submission)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing UserID with users' features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_explicit_2 = train_explicit_1.merge(users,\n",
    "                                        left_on='UserID', right_on='User-ID', how='left')\n",
    "train_all_2 = train_all_1.merge(users, left_on='UserID', right_on='User-ID', how='left')\n",
    "test_submission_2 = test_submission_1.merge(users,\n",
    "                                          left_on='UserID', right_on='User-ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_explicit_2['Age'] = pd.to_numeric(train_explicit_2.Age, errors='coerce')\n",
    "train_all_2['Age'] = pd.to_numeric(train_all_2.Age, errors='coerce')\n",
    "test_submission_2['Age'] = pd.to_numeric(test_submission_2.Age, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_age = train_all_2['Age'].mean()\n",
    "train_explicit_2['Age'].fillna(average_age, inplace=True)\n",
    "train_all_2['Age'].fillna(average_age, inplace=True)\n",
    "test_submission_2['Age'].fillna(average_age, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_explicit_missing_user = train_explicit_2[train_explicit_2.isnull().any(axis=1)]\n",
    "train_all_missing_user = train_all_2[train_all_2.isnull().any(axis=1)]\n",
    "test_submission_missing_user = test_submission_2[test_submission_2.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(str(len(train_explicit_missing_user)) + \" / \" + str(len(train_explicit)))\n",
    "print(str(len(train_all_missing_user)) + \" / \" + str(len(train_all)))\n",
    "print(str(len(test_submission_missing_user)) + \" / \" + str(len(test_submission)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher',\n",
    "            'Location', 'Age',\n",
    "            'Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_explicit_2 = train_explicit_2[features]\n",
    "train_all_2 = train_all_2[features]\n",
    "test_submission_2 = test_submission_2[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(train_explicit_2, open('./data/feature-based/train_explicit.pcl', 'wb'))\n",
    "pickle.dump(train_all_2, open('./data/feature-based/train_all.pcl', 'wb'))\n",
    "pickle.dump(test_submission_2, open('./data/feature-based/test_submission.pcl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Inputs for SVD & NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "re-create user ids, and book ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41636 56489\n",
      "113326 232625\n"
     ]
    }
   ],
   "source": [
    "print len(train_explicit.UserID.unique()), len(train_all.UserID.unique())\n",
    "print len(train_explicit.BookID.unique()), len(train_all.BookID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_explicit_ws = train_explicit.append(test_submission)\n",
    "df_users = pd.DataFrame(train_explicit_ws.UserID.unique()).reset_index()\n",
    "df_books = pd.DataFrame(train_explicit_ws.BookID.unique()).reset_index()\n",
    "df_users.columns = ['user_id', 'id']\n",
    "df_books.columns = ['book_id', 'id']\n",
    "\n",
    "train_explicit_m = train_explicit_ws.merge(df_books, left_on='BookID', right_on='id', how='left')\n",
    "train_explicit_m = train_explicit_m.merge(df_users, left_on='UserID', right_on='id', how='left')\n",
    "train_explicit_m = train_explicit_m[['UserID', 'BookID', 'BookID_org',\n",
    "                                     'user_id', 'book_id',\n",
    "                                     'Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_all_ws = train_all.append(test_submission)\n",
    "df_users = pd.DataFrame(train_all_ws.UserID.unique()).reset_index()\n",
    "df_books = pd.DataFrame(train_all_ws.BookID.unique()).reset_index()\n",
    "df_users.columns = ['user_id', 'id']\n",
    "df_books.columns = ['book_id', 'id']\n",
    "\n",
    "train_all_m = train_all_ws.merge(df_books, left_on='BookID', right_on='id', how='left')\n",
    "train_all_m = train_all_m.merge(df_users, left_on='UserID', right_on='id', how='left')\n",
    "train_all_m = train_all_m[['UserID', 'BookID', 'BookID_org',\n",
    "                           'user_id', 'book_id',\n",
    "                           'Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_explicit_m = train_explicit.copy()\n",
    "# train_explicit_m['BookID'].replace(to_replace='[^0-9]+', value='', inplace=True, regex=True)\n",
    "# train_explicit_m['BookID'] = pd.to_numeric(train_explicit_m.BookID, errors='raise')\n",
    "# train_explicit_m = train_explicit_m.dropna()\n",
    "# print len(train_explicit_m), \" / \", len(train_explicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_all_m = train_all.copy()\n",
    "# train_all_m['BookID'].replace(to_replace='[^0-9]+', value='', inplace=True, regex=True)\n",
    "# train_all_m['BookID'] = pd.to_numeric(train_all_m.BookID, errors='raise')\n",
    "# train_all_m = train_all_m.dropna()\n",
    "# print len(train_all_m), \" / \", len(train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_submission_m = test_submission.copy()\n",
    "# test_submission_m['BookID'].replace(to_replace='[^0-9]+', value='', inplace=True, regex=True)\n",
    "# test_submission_m['BookID'] = pd.to_numeric(test_submission_m.BookID, errors='raise')\n",
    "# test_submission_m = test_submission_m.dropna()\n",
    "# print len(test_submission_m), \" / \", len(test_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>BookID</th>\n",
       "      <th>BookID_org</th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126788</td>\n",
       "      <td>0553284363</td>\n",
       "      <td>553284363</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126788</td>\n",
       "      <td>0743458680</td>\n",
       "      <td>743458680</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126788</td>\n",
       "      <td>0752848062</td>\n",
       "      <td>752848062</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126788</td>\n",
       "      <td>0786866020</td>\n",
       "      <td>786866020</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126788</td>\n",
       "      <td>1857238583</td>\n",
       "      <td>1857238583</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID      BookID  BookID_org  user_id  book_id  Rating\n",
       "0  126788  0553284363   553284363        0        0     9.0\n",
       "1  126788  0743458680   743458680        0        1     7.0\n",
       "2  126788  0752848062   752848062        0        2     9.0\n",
       "3  126788  0786866020   786866020        0        3    10.0\n",
       "4  126788  1857238583  1857238583        0        4    10.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(train_explicit_m, open('./data/id-based/train_explicit_m.pcl', 'wb'))\n",
    "pickle.dump(train_all_m, open('./data/id-based/train_all_m.pcl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging and Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_explicit_grouped_by_user.mean()['Rating'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_implicit_conversion.groupby('UserID').mean()['Rating'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adjusted_ratings.groupby('BookID').mean()['Rating'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiple ratings for same user same item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = train_explicit.groupby(['UserID', 'BookID'])\n",
    "duplicates = g.filter(lambda x: len(x) > 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building user-item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_item_matrix_1 = train_explicit.pivot_table(index='UserID', columns='BookID', values='Rating')\n",
    "pickle.dump(user_item_matrix_1, open('user_item_matrix_1.pcl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_item_matrix_2 = train_all.pivot(index='UserID', columns='BookID', values=\"Rating\")\n",
    "pickle.dump(user_item_matrix_2, open('user_item_matrix_2.pcl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pickle.load(open('./data/test_submission.pcl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
